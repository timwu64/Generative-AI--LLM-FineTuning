{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timwu64/Generative-AI---LoRA-FineTuning/blob/main/LightweightFineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f35354cd",
      "metadata": {
        "id": "f35354cd"
      },
      "source": [
        "# Lightweight Fine-Tuning Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "560fb3ff",
      "metadata": {
        "id": "560fb3ff"
      },
      "source": [
        "TODO: In this cell, describe your choices for each of the following\n",
        "\n",
        "* PEFT technique: LoRa\n",
        "* Model: bert-base-cased\n",
        "* Evaluation approach: accuracy\n",
        "* Fine-tuning dataset: imdb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de8d76bb",
      "metadata": {
        "id": "de8d76bb"
      },
      "source": [
        "## Loading and Evaluating a Foundation Model\n",
        "\n",
        "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d35f753c",
      "metadata": {
        "id": "d35f753c"
      },
      "outputs": [],
      "source": [
        "# Install the required version of datasets in case you have an older version\n",
        "# You will need to choose \"Kernel > Restart Kernel\" from the menu after executing this cell\n",
        "# ! pip install -q \"datasets==2.15.0\"\n",
        "# ! pip install scikit-learn\n",
        "# ! pip install datasets\n",
        "# ! pip install transformers\n",
        "# ! pip install peft\n",
        "# ! pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4935cb4d",
      "metadata": {
        "id": "4935cb4d"
      },
      "outputs": [],
      "source": [
        "# Includes the relevant imports\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f28c4a78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f28c4a78",
        "outputId": "a829ef86-3556-4509-9913-6ca05512ab35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Define the Foundation Model\n",
        "\n",
        "base_model = \"bert-base-cased\"\n",
        "peft_model_name = base_model+'-peft'\n",
        "modified_base = base_model+'-modified'\n",
        "\n",
        "\n",
        "# Tokenize the dataset with the foundation model\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "\n",
        "# Load a pretrained Hugging Face model that can be used for sequence classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    base_model,\n",
        "    num_labels=2,\n",
        "    id2label={0: \"NEGATIVE\", 1: \"POSITIVE\"},  # For converting predictions to strings\n",
        "    label2id={\"NEGATIVE\": 0, \"POSITIVE\": 1},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "019b9f55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8e11ad09e44a4e84bf44fb686b2ab122",
            "c28ef0bddb8540feb437c3e19232a7be",
            "eac81e6a1dda49da85bb6df614bb07b8",
            "eab76ebe43ae4dc486a7c08611fc3067",
            "e126d4e31def476e90bcb0f33d1de0d8",
            "d9689c48470248a8855d0db9d063d296",
            "49fe22c519c744d98afcf67b6d93ec30",
            "fe1836c004a34c4f9e650e976b33a37b",
            "48d4d06812c646bc8f5b1b3b98780cf3",
            "f541bfb2db304dc6b9eefc70cb47dce5",
            "438c50ece9c94ba0a911f501dcefcc74"
          ]
        },
        "id": "019b9f55",
        "outputId": "8e97b4e1-8857-4b2a-9241-5559f05bbc91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e11ad09e44a4e84bf44fb686b2ab122"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Includes the relevant imports and loads a Hugging Face dataset that can be used for sequence classification.\n",
        "# Load and preprocess a dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Define the dataset\n",
        "dataset_name = \"imdb\"\n",
        "\n",
        "# Set dataset range\n",
        "dataset_range = 1000\n",
        "\n",
        "# Import the datasets and transformers packages\n",
        "dataset = load_dataset(dataset_name)\n",
        "\n",
        "# preprocess the dataset by returning tokenized examples\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Includes relevant imports and loads a Hugging Face tokenizer that can be used to prepare the dataset.\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# A subset of the full dataset to be used to reduce computational resources needed.\n",
        "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=SEED).select(range(dataset_range))\n",
        "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=SEED).select(range(dataset_range))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "026e1baa",
      "metadata": {
        "id": "026e1baa"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\"accuracy\": accuracy_score(labels, predictions)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e4b54748",
      "metadata": {
        "id": "e4b54748"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "# hyperparameters\n",
        "lr = 1e-3\n",
        "batch_size = 16\n",
        "num_epochs = 8\n",
        "\n",
        "# Define training args for base\n",
        "training_args_base = TrainingArguments(\n",
        "    output_dir='./foundation_results',\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "74864619",
      "metadata": {
        "id": "74864619"
      },
      "outputs": [],
      "source": [
        "trainer_base = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_base,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "01d9ccbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "01d9ccbb",
        "outputId": "95b5ba5f-1819-48bc-f28a-820092444d44"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:29]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained Model: 0.516\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the pretrained model\n",
        "# Accuracy classification metric is calculated using the dataset and pretrained model\n",
        "base_results = trainer_base.evaluate()\n",
        "print(\"Pre-trained Model:\", base_results['eval_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d52a229",
      "metadata": {
        "id": "4d52a229"
      },
      "source": [
        "## Performing Parameter-Efficient Fine-Tuning\n",
        "\n",
        "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5775fadf",
      "metadata": {
        "id": "5775fadf"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, TaskType\n",
        "\n",
        "# Initializes a Hugging Face PEST config\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS, r=1, lora_alpha=1, lora_dropout=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "894046c0",
      "metadata": {
        "id": "894046c0"
      },
      "outputs": [],
      "source": [
        "# Includes the relveant imports\n",
        "from peft import get_peft_model\n",
        "\n",
        "# Creates a PEFT model using the config\n",
        "peft_model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c4d4c908",
      "metadata": {
        "id": "c4d4c908"
      },
      "outputs": [],
      "source": [
        "# Define training args for peft\n",
        "training_args_peft = TrainingArguments(\n",
        "    output_dir='./prft_results',\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "47e859cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47e859cd",
        "outputId": "481b57d0-fd26-4525-d460-19b704566587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PEFT Model\n",
            "trainable params: 38,402 || all params: 108,350,212 || trainable%: 0.03544247795288116\n"
          ]
        }
      ],
      "source": [
        "print('PEFT Model')\n",
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b47abf88",
      "metadata": {
        "id": "b47abf88"
      },
      "outputs": [],
      "source": [
        "trainer_peft = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args_peft,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "fa7fe003",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "fa7fe003",
        "outputId": "1f950512-3c8c-4e5a-90ae-62ad83f334c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PEFT Model\n",
            "trainable params: 38,402 || all params: 108,350,212 || trainable%: 0.03544247795288116\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [504/504 14:05, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.723889</td>\n",
              "      <td>0.583000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.389572</td>\n",
              "      <td>0.846000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.357224</td>\n",
              "      <td>0.864000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.361418</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.381158</td>\n",
              "      <td>0.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.333674</td>\n",
              "      <td>0.879000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.369139</td>\n",
              "      <td>0.877000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.328400</td>\n",
              "      <td>0.361570</td>\n",
              "      <td>0.877000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=504, training_loss=0.3264605936313432, metrics={'train_runtime': 846.4772, 'train_samples_per_second': 9.451, 'train_steps_per_second': 0.595, 'total_flos': 2105832210432000.0, 'train_loss': 0.3264605936313432, 'epoch': 8.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Train the PRFT model\n",
        "\n",
        "print('PEFT Model')\n",
        "peft_model.print_trainable_parameters()\n",
        "trainer_peft.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0182a133",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "0182a133",
        "outputId": "93a85c8d-20fc-4325-e6c5-c04fb55e6c09"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:33]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compare the result for Pre-trained and PEFT Model:\n",
            "Pre-trained Model: 0.516\n",
            "PEFT Model: 0.879\n"
          ]
        }
      ],
      "source": [
        "peft_results = trainer_peft.evaluate()\n",
        "print(\"Compare the result for Pre-trained and PEFT Model:\")\n",
        "print(\"Pre-trained Model:\", base_results['eval_accuracy'])\n",
        "print(\"PEFT Model:\", peft_results['eval_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the PEFT model, Fine-tuened parameters are saved to a separate directory. The saved weights directory should be the same home directory as the notebook file\n",
        "\n",
        "# Save our LoRA model & tokenizer results\n",
        "peft_model.save_pretrained(peft_model_name)\n",
        "tokenizer.save_pretrained(modified_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ddi6mPptaqq",
        "outputId": "b93c986d-453b-485a-bd82-ba13a787af84"
      },
      "id": "3Ddi6mPptaqq",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bert-base-cased-modified/tokenizer_config.json',\n",
              " 'bert-base-cased-modified/special_tokens_map.json',\n",
              " 'bert-base-cased-modified/vocab.txt',\n",
              " 'bert-base-cased-modified/added_tokens.json',\n",
              " 'bert-base-cased-modified/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "615b12c6",
      "metadata": {
        "id": "615b12c6"
      },
      "source": [
        "## Performing Inference with a PEFT Model\n",
        "\n",
        "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "863ec66e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "863ec66e",
        "outputId": "9d8270f4-8c99-4474-cd75-1205775170b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Peft model loaded\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Load peft config for pre-trained checkpoint etc.\n",
        "config = PeftConfig.from_pretrained(peft_model_name)\n",
        "\n",
        "# LOAD the Saved PEFT model\n",
        "tokenizer = AutoTokenizer.from_pretrained(modified_base)\n",
        "\n",
        "# Load the Lora model\n",
        "model = PeftModel.from_pretrained(model, peft_model_name, device_map={\"\":0})\n",
        "model.eval()\n",
        "\n",
        "print(\"Peft model loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bc3a8147",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "bc3a8147",
        "outputId": "44d1b7b1-1d72-46f7-9e0c-6f9f7ef176b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 00:33]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained Model: 0.516\n",
            "Loaded PEFT Model: 0.879\n"
          ]
        }
      ],
      "source": [
        "# create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer_loaded_peft = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_base,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Evaluate the Peft model\n",
        "# Accuracy classification metric is calculated using the dataset and pretrained model\n",
        "loaded_peft_results = trainer_loaded_peft.evaluate()\n",
        "print(\"Pre-trained Model:\", base_results['eval_accuracy'])\n",
        "print(\"Loaded PEFT Model:\", loaded_peft_results['eval_accuracy'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e11ad09e44a4e84bf44fb686b2ab122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c28ef0bddb8540feb437c3e19232a7be",
              "IPY_MODEL_eac81e6a1dda49da85bb6df614bb07b8",
              "IPY_MODEL_eab76ebe43ae4dc486a7c08611fc3067"
            ],
            "layout": "IPY_MODEL_e126d4e31def476e90bcb0f33d1de0d8"
          }
        },
        "c28ef0bddb8540feb437c3e19232a7be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9689c48470248a8855d0db9d063d296",
            "placeholder": "​",
            "style": "IPY_MODEL_49fe22c519c744d98afcf67b6d93ec30",
            "value": "Map: 100%"
          }
        },
        "eac81e6a1dda49da85bb6df614bb07b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe1836c004a34c4f9e650e976b33a37b",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48d4d06812c646bc8f5b1b3b98780cf3",
            "value": 50000
          }
        },
        "eab76ebe43ae4dc486a7c08611fc3067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f541bfb2db304dc6b9eefc70cb47dce5",
            "placeholder": "​",
            "style": "IPY_MODEL_438c50ece9c94ba0a911f501dcefcc74",
            "value": " 50000/50000 [00:56&lt;00:00, 1112.97 examples/s]"
          }
        },
        "e126d4e31def476e90bcb0f33d1de0d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9689c48470248a8855d0db9d063d296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49fe22c519c744d98afcf67b6d93ec30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe1836c004a34c4f9e650e976b33a37b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d4d06812c646bc8f5b1b3b98780cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f541bfb2db304dc6b9eefc70cb47dce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438c50ece9c94ba0a911f501dcefcc74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}